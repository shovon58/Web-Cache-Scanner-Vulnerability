package pkg

import (
	"crypto/tls"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"strings"
	"sync"

	"golang.org/x/net/html"
)

var impactfulQueries []string

func init() {
}

/* Scan cookies for poisoning */
func ScanCookies() Result {
	var result Result
	result.Technique = "Cookies"
	for i := 0; i < len(Config.Website.Cookies); i++ {

		poison := randInt()
		msg := fmt.Sprintf("Checking cookie %s\n", Config.Website.Cookies[i].Name)
		Print(msg, NoColor)
		urlCb, cb := addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)
		success := fmt.Sprintf("------- Cookie %s was successfully poisoned!!! cb: %s poison: %s -------\n", Config.Website.Cookies[i].Name, cb, poison)
		identifier := Config.Website.Cookies[i].String() + "=" + Config.Website.Cookies[i].Value
		msg = fmt.Sprintf("Overwriting %s=%s with %s=%s\n", Config.Website.Cookies[i].Name, Config.Website.Cookies[i].Value, Config.Website.Cookies[i].Name, poison)
		Print(msg, NoColor)
		oldValue := Config.Website.Cookies[i].Value
		Config.Website.Cookies[i].Value = poison

		rp := requestParams{
			result:           &result,
			headers:          []string{""},
			values:           []string{""},
			identifier:       identifier,
			poison:           poison,
			url:              urlCb,
			cb:               cb,
			success:          success,
			bodyString:       "",
			forcePost:        false,
			duplicateHeaders: false,
			m:                nil,
			cookie: oldCookie{
				position: i,
				oldValue: oldValue,
			},
		}
		responseSplitting, _ := issueRequest(rp)

		// check for response splitting, if poison was reflected in a header
		if responseSplitting {
			msg := fmt.Sprintf("Checking cookie %s for response splitting\n", Config.Website.Cookies[i].Name)
			Print(msg, NoColor)

			rp.poison += getRespSplit()
			rp.url, rp.cb = addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)
			rp.success = fmt.Sprintf("------- Cookie %s was successfully poisoned with response splitting!!! cb: %s poison: %s -------\n", Config.Website.Cookies[i].Name, rp.cb, rp.poison)
			rp.identifier += " response splitting"

			msg = fmt.Sprintf("Overwriting %s=%s with %s=%s\n", Config.Website.Cookies[i].Name, Config.Website.Cookies[i].Value, Config.Website.Cookies[i].Name, rp.poison)
			Print(msg, NoColor)
			Config.Website.Cookies[i].Value = rp.poison

			issueRequest(rp)
		}
	}
	return result
}

func ScanForwardingHeaders() Result {
	var result Result
	result.Technique = "Forward/Host Headers"

	// Host header
	header := "Host"
	values := []string{":31337", ":@31337", " 31337"}
	for _, value := range values {
		ForwardHeadersTemplate(&result, []string{header}, []string{value}, header, value, false)
	}

	// Duplicate Host header
	header = "host"
	poison := randInt()
	values = []string{poison}
	for _, value := range values {
		ForwardHeadersTemplate(&result, []string{header}, []string{value}, header, value, true)
	}

	// X-Forwarded Headers
	headers := []string{"X-Forwarded-Host", "X-Forwarded-Scheme"}
	poison = randInt()
	values = []string{poison, "nothttps"}
	identifier := "X-Forwarded-Host and X-Forwarded-Scheme"
	ForwardHeadersTemplate(&result, headers, values, identifier, poison, false)

	// Forwarded Header
	header = "Forwarded"
	value := "host=" + randInt()
	ForwardHeadersTemplate(&result, []string{header}, []string{value}, header, value, false)

	// X-Forwarded-Port Header
	header = "X-Forwarded-Port"
	value = "31337"
	ForwardHeadersTemplate(&result, []string{header}, []string{value}, header, value, false)

	return result
}

func ForwardHeadersTemplate(result *Result, headers []string, values []string, identifier string, poison string, duplicateHeaders bool) {
	urlCb, cb := addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)

	success := fmt.Sprintf("------- %s was successfully poisoned!!! cb: %s poison: %s -------\n", headers, cb, values)

	rp := requestParams{
		result:           result,
		headers:          headers,
		values:           values,
		identifier:       identifier,
		poison:           poison,
		url:              urlCb,
		cb:               cb,
		success:          success,
		bodyString:       "",
		forcePost:        false,
		duplicateHeaders: duplicateHeaders,
		m:                nil,
		cookie:           oldCookie{},
	}
	responseSplitting, _ := issueRequest(rp)

	// check for response splitting, if poison was reflected in a header
	if responseSplitting {
		rp.values[0] += getRespSplit()
		msg := fmt.Sprintf("Checking header(s) %s with value(s) %s for response splitting\n", rp.headers, rp.values)
		Print(msg, NoColor)

		rp.poison += getRespSplit()
		rp.url, rp.cb = addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)
		rp.success = fmt.Sprintf("------- %s was successfully poisoned with response splitting!!! cb: %s poison: %s -------\n", headers, rp.cb, rp.values)
		rp.identifier += " response splitting"

		issueRequest(rp)
	}
}

func ScanHTTPRequestSmuggling(proxyURL *url.URL, tlsConfig *tls.Config) Result {
	var result Result
	identifier := "HTTP Request Smuggling"
	result.Technique = identifier

	headers := GenerateHeaderString()

	PrintVerbose("Trying CLTE Request Smuggling\n", NoColor, 1)
	req := clte(headers)
	httpRequestSmuggling(req, &result, proxyURL, tlsConfig)

	PrintVerbose("Trying TECL Request Smuggling\n", NoColor, 1)
	req = tecl(headers)
	httpRequestSmuggling(req, &result, proxyURL, tlsConfig)

	PrintVerbose("Trying CLCL Request Smuggling\n", NoColor, 1)
	req = clcl(headers)
	httpRequestSmuggling(req, &result, proxyURL, tlsConfig)

	PrintVerbose("Trying CLCL2 Request Smuggling\n", NoColor, 1)
	req = clcl2(headers)
	httpRequestSmuggling(req, &result, proxyURL, tlsConfig)

	return result
}

/* Scan headers for poisoning */
func ScanHeaders(headerList []string) Result {
	var result Result
	result.Technique = "Headers"

	//c := make(chan result) //<- needed?
	sem := make(chan int, Config.Threads)
	var wg sync.WaitGroup
	wg.Add(len(headerList))
	var m sync.Mutex

	for i, header := range headerList {
		header = strings.Trim(header, "\r")
		if header == "" {
			msg := fmt.Sprintf("Skipping empty header (%d/%d)\n", i+1, len(headerList))
			PrintVerbose(msg, NoColor, 1)

			wg.Done()
			continue
		}

		header = http.CanonicalHeaderKey(header)

		poison := randInt()

		go func(i int, header string, poison string) {
			defer wg.Done()
			sem <- 1

			msg := fmt.Sprintf("Testing now (%d/%d) %s\n", i+1, len(headerList), header)
			PrintVerbose(msg, NoColor, 2)
			urlCb, cb := addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)
			success := fmt.Sprintf("------- Header %s was successfully poisoned!!! cb: %s poison: %s -------\n", header, cb, poison)
			identifier := fmt.Sprintf("header %s", header)

			rp := requestParams{
				result:           &result,
				headers:          []string{header},
				values:           []string{poison},
				identifier:       identifier,
				poison:           poison,
				url:              urlCb,
				cb:               cb,
				success:          success,
				bodyString:       "",
				forcePost:        false,
				duplicateHeaders: false,
				m:                &m,
				cookie:           oldCookie{},
			}
			responseSplitting, _ := issueRequest(rp)

			// check for response splitting, if poison was reflected in a header
			if responseSplitting {
				msg := fmt.Sprintf("Testing now (%d/%d) %s for response splitting\n", i+1, len(headerList), header)
				Print(msg, NoColor)

				rp.url, rp.cb = addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)
				rp.poison += getRespSplit()
				rp.success = fmt.Sprintf("------- Header %s was successfully poisoned with response splitting!!! cb: %s poison: %s -------\n", header, rp.cb, rp.poison)
				rp.identifier += " response splitting"

				issueRequest(rp)
			}

			<-sem
		}(i, header, poison)

	}
	wg.Wait()

	return result
}

/* Scan query parameters for poisoning */
func ScanParameters(parameterList []string) Result {
	var result Result
	result.Technique = "Parameters"

	//c := make(chan result) //<- needed?
	sem := make(chan int, Config.Threads)
	var wg sync.WaitGroup
	wg.Add(len(parameterList))
	var m sync.Mutex

	impactfulQueries = nil

	for i, parameter := range parameterList {
		if parameter == "" {
			msg := fmt.Sprintf("Skipping empty query (%d/%d) %s\n", i+1, len(parameterList), parameter)
			PrintVerbose(msg, NoColor, 2)
			wg.Done()
			continue
		}

		poison := randInt()

		go func(i int, parameter string, poison string) {
			defer wg.Done()
			sem <- 1

			parameter = strings.Trim(parameter, "\r")
			msg := fmt.Sprintf("Testing now Parameter (%d/%d) %s\n", i+1, len(parameterList), parameter)
			PrintVerbose(msg, NoColor, 2)
			var urlCb, cb string
			if _, ok := Config.Website.Queries[parameter]; ok {
				// if the query to add is already present
				queryParameterMap := make(map[string]string)

				for key, val := range Config.Website.Queries {
					queryParameterMap[key] = val
				}

				msg := fmt.Sprintf("Overwriting %s=%s with %s=%s\n", parameter, queryParameterMap[parameter], parameter, poison)
				Print(msg, NoColor)
				queryParameterMap[parameter] = poison

				urlCb = Config.Website.BaseUrlStr + "?"
				for key, val := range queryParameterMap {
					if !strings.HasSuffix(urlCb, "?") {
						urlCb += "&"
					}
					urlCb += key + "=" + val
				}

				urlCb, cb = addCacheBuster(urlCb+Config.QuerySeperator, "", Config.CacheBuster)
			} else {
				// if query isn't already present, just add it and the cachebuster
				urlCb = Config.Website.Url.String()
				urlCb += parameter + "=" + poison + Config.QuerySeperator
				urlCb, cb = addCacheBuster(urlCb, "", Config.CacheBuster)
			}
			success := fmt.Sprintf("------- Query Parameter %s was successfully poisoned!!! cb: %s poison: %s -------\n", parameter, cb, poison)
			identifier := fmt.Sprintf("parameter %s", parameter)

			rp := requestParams{
				result:           &result,
				headers:          []string{""},
				values:           []string{poison},
				identifier:       identifier,
				poison:           poison,
				url:              urlCb,
				cb:               cb,
				success:          success,
				bodyString:       "",
				forcePost:        false,
				duplicateHeaders: false,
				m:                &m,
				cookie:           oldCookie{},
			}
			appendParameter, responseSplitting := issueRequest(rp)
			if appendParameter {
				impactfulQueries = append(impactfulQueries, parameter)
			}
			if responseSplitting {
				//requestParams.
				//issueRequest(rp)
				//TODO
			}

			<-sem
		}(i, parameter, poison)

	}
	wg.Wait()

	return result
}

/* Check for fat GET */
func ScanFatGET() Result {
	var result Result
	result.Technique = "Fat GET"

	if len(impactfulQueries) == 0 {
		msg := "No impactful query parameters were found beforehand. Run the query parameter scan (maybe with a different wordlist)."
		Print(msg+"\n", Yellow)
		result.HasError = true
		result.ErrorMessages = append(result.ErrorMessages, msg)
		return result
	} else {
		msg := fmt.Sprintf("The following parameters were found to be impactful and will be tested for parameter cloaking: %s\n", impactfulQueries)
		Print(msg, NoColor)
	}

	//c := make(chan result) //<- needed?
	sem := make(chan int, Config.Threads)
	var wg sync.WaitGroup
	wg.Add(len(impactfulQueries))
	var m sync.Mutex

	headers := []string{"", "", "X-HTTP-Method-Override", "X-HTTP-Method", "X-Method-Override"}
	values := []string{"", "", "POST", "POST", "POST"}

	for method := 0; method < 5; method++ {
		var identifier string
		forcePost := false
		if method == 0 {
			identifier = "simple Fat GET"
		} else if method == 1 {
			identifier = "POST Fat GET"
			forcePost = true
		} else {
			identifier = fmt.Sprintf("%s Fat GET", headers[method-2])
		}
		msg := "Testing now " + identifier + "\n"
		Print(msg, NoColor)

		for i, s := range impactfulQueries {

			poison := randInt()

			go func(i int, s string, poison string) {
				defer wg.Done()
				sem <- 1

				msg := fmt.Sprintf("(%d/%d) %s\n", i+1, len(impactfulQueries), s)
				PrintVerbose(msg, NoColor, 2)
				urlCb, cb := addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)
				bodyString := s + "=" + poison
				success := fmt.Sprintf("------- Query Parameter %s was successfully poisoned via %s!!! cb: %s poison:%s -------\n", s, identifier, cb, poison)

				rp := requestParams{
					result:           &result,
					headers:          []string{headers[method]},
					values:           []string{values[method]},
					identifier:       identifier,
					poison:           poison,
					url:              urlCb,
					cb:               cb,
					success:          success,
					bodyString:       bodyString,
					forcePost:        forcePost,
					duplicateHeaders: false,
					m:                &m,
					cookie:           oldCookie{},
				}
				responseSplitting, _ := issueRequest(rp)

				// check for response splitting, if poison was reflected in a header
				if responseSplitting {
					msg := fmt.Sprintf("Testing now (%d/%d) %s for response splitting\n", i+1, len(impactfulQueries), s)
					Print(msg, NoColor)

					rp.url, rp.cb = addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)
					rp.poison += getRespSplit()
					rp.bodyString += getRespSplit()
					rp.identifier += " response splitting"
					rp.success = fmt.Sprintf("------- Query Parameter %s was successfully poisoned via %s with response splitting!!! cb: %s poison:%s -------\n", s, identifier, rp.cb, rp.poison)

					issueRequest(rp)
				}

				<-sem
			}(i, s, poison)
		}
		wg.Wait()
		wg.Add(len(impactfulQueries))
	}

	return result
}

/* Check for Parameter Cloaking */
func ScanParameterCloaking() Result {
	var result Result
	result.Technique = "Parameter Cloaking"

	if len(impactfulQueries) == 0 {
		msg := "No impactful query parameters were found beforehand. Run the query parameter scan (maybe with a different wordlist)."
		Print(msg+"\n", Yellow)
		result.HasError = true
		result.ErrorMessages = append(result.ErrorMessages, msg)
		return result
	} else {
		msg := fmt.Sprintf("The following parameters were found to be impactful and will be tested for parameter cloaking:\n%s\n", impactfulQueries)
		Print(msg, NoColor)
	}

	utm_parameter := []string{"utm_source", "utm_medium", "utm_campaign", "utm_content", "utm_term"}
	unkeyed_parameter := []string{}

	urlCb, _ := addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)

	/***********Check if urlCb already contains utm parameter.
				Check if ? or querySeperator is needed
	****************/

	// The first request is made so a cache miss is forced and the following responses will only
	//have a cache hit, if they are unkeyed

	identifier := "first request %s"
	firstRequest(urlCb, identifier, []string{""}, []string{""}, "", false, false)

	sem := make(chan int, Config.Threads)
	var wg sync.WaitGroup
	var m sync.Mutex

	if Config.Website.Cache.Indicator == "" {
		//Cant test if utm_parameter are unkeyed if X-Cache isn't set
		//So they will be all added as unkeyed_parameter
		msg := "hit/miss isn't verbose. Can't check which utm_parameter is unkeyed, so all will be used\n"
		Print(msg, Yellow)
		unkeyed_parameter = utm_parameter
	} else {
		//Test which utm_parameter are unkeyed
		//c := make(chan result) //<- needed?

		wg.Add(len(utm_parameter))

		for i, s := range utm_parameter {
			go func(i int, s string) {
				defer wg.Done()
				sem <- 1

				msg := fmt.Sprintf("Testing now for unkeyed utm parameters (%d/%d) %s\n", i+1, len(utm_parameter), s)
				PrintVerbose(msg, NoColor, 2)

				// add utm parameter after cachebuster. give utm parameter nonsense value
				urlPoisoned := urlCb + Config.QuerySeperator + s + "=foobar"
				identifier := fmt.Sprintf("unkeyed utm %s", s)
				//TODO: TimeOut behandeln!!!
				_, _, _, respHeader, err := firstRequest(urlPoisoned, identifier, []string{""}, []string{""}, "", false, false)
				if err == nil && respHeader != nil && strings.Contains(strings.ToLower(respHeader.Get(Config.Website.Cache.Indicator)), "hit") {
					m.Lock()
					unkeyed_parameter = append(unkeyed_parameter, s)
					m.Unlock()
				} else if err != nil && err.Error() != "stop" {
					m.Lock()
					result.HasError = true
					result.ErrorMessages = append(result.ErrorMessages, err.Error())
					m.Unlock()
				}
			}(i, s)
		}
		wg.Wait()
	}

	if len(unkeyed_parameter) == 0 {
		msg := "No unkeyed utm parameters could be found. Parameter Cloaking is not possible using utm parameters\n"
		Print(msg, Yellow)
	} else {
		msg := fmt.Sprintf("The following utm parameters were found to be unkeyed and will be tested for parameter cloaking:\n %s\n", unkeyed_parameter)
		Print(msg, NoColor)
	}

	cloak := ";"
	if Config.QuerySeperator == ";" {
		cloak = "&"
	}

	for iu, u := range unkeyed_parameter {

		//test one unkeyed parameter with all impactfulQueries one after another
		wg.Add(len(impactfulQueries))

		for is, s := range impactfulQueries {

			poison := randInt()

			go func(iu int, u string, is int, s string, poison string) {
				defer wg.Done()
				sem <- 1

				msg := fmt.Sprintf("Testing now Parameter Cloaking (%d/%d) %s%s%s\n", iu+is+1, len(impactfulQueries)*len(unkeyed_parameter), u, cloak, s)
				PrintVerbose(msg, NoColor, 2)
				urlCb, cb := addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)
				urlPoisoned := urlCb + Config.QuerySeperator + u + "=foobar" + cloak + s + "=" + poison
				success := fmt.Sprintf("------- Query Parameter %s was successfully poisoned via Parameter Cloaking using %s!!! cb:%s poison:%s -------\n", s, u, cb, poison)
				identifier := fmt.Sprintf("parameter cloaking %s %s", u, s)

				rp := requestParams{
					result:           &result,
					headers:          []string{""},
					values:           []string{poison},
					identifier:       identifier,
					poison:           poison,
					url:              urlPoisoned,
					cb:               cb,
					success:          success,
					bodyString:       "",
					forcePost:        false,
					duplicateHeaders: false,
					m:                &m,
					cookie:           oldCookie{},
				}
				responseSplitting, _ := issueRequest(rp)

				// check for response splitting, if poison was reflected in a header
				if responseSplitting {
					msg := fmt.Sprintf("Testing now Parameter Cloaking (%d/%d) %s%s%s for response splitting\n", iu+is+1, len(impactfulQueries)*len(unkeyed_parameter), u, cloak, s)
					Print(msg, NoColor)

					urlCb, rp.cb = addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)
					rp.poison += getRespSplit()
					rp.url = urlCb + Config.QuerySeperator + u + "=foobar" + cloak + s + "=" + rp.poison
					rp.success = fmt.Sprintf("------- Query Parameter %s was successfully poisoned via Parameter Cloaking using %s with parameter cloaking!!! cb:%s poison:%s -------\n", s, u, rp.cb, rp.poison)
					rp.identifier += " response splitting"

					issueRequest(rp)
				}

				<-sem
			}(iu, u, is, s, poison)
		}
		wg.Wait()
	}

	return result
}

/* Check for different DOS techniques */
func DOS() Result {
	var result Result
	result.Technique = "DOS"

	// TODO: Ist nur Header Value oder auch Header Name ausschlaggebend?
	hho(&result)

	// HMC (Header Metachar Character)
	// TODO: Check for more META CHARACTERS?
	//TODO: Change to other header, which is probably whitelisted
	headers := []string{"X-Metachar-Header"}
	values := []string{"\\n", "\\r", "\\a", "\\0", "\\b", "\\e", "\\v", "\\f", "\\u0000"}

	for _, header := range headers {
		headerDOSTemplate(&result, values, header, "HMC ", true)
	}

	// HMO (HTTP Method Override)
	// TODO: Add more HEADERS/METHODS?
	values = []string{"GET", "POST", "DELETE", "NONSENSE"}
	headers = []string{"X-HTTP-Method-Override", "X-HTTP-Method", "X-Method-Override"}
	for _, header := range headers {
		headerDOSTemplate(&result, values, header, "HMO ", true)
	}

	// DOS via not implemented transferEncoding
	values = []string{"asdf"}
	headerDOSTemplate(&result, values, "zTRANSFER-ENCODING", "Not supported Transfer-Encoding ", true)

	// DOS via incompatible/outdated browser agent
	// TODO: Add more USERAGENTS?
	values = []string{"Mozilla/5.0 (Windows; U; MSIE 9.0; WIndows NT 9.0; en-US))"}
	headerDOSTemplate(&result, values, "User-Agent", "incompatible browser ", true)

	// DOS via Max-Forwards (Webserver/Cache returns request)
	values = []string{"0", "1", "2"}
	headerDOSTemplate(&result, values, "Max-Forwards", "", true)

	// DOS via waf blocking because of a blacklist word
	// TODO: change header to probably whitelisted header, More Blacklist words?
	values = []string{".burpcollaborator.net", "<script>alert(1)</script>"}
	headerDOSTemplate(&result, values, "Any-Header", "blacklist ", true)

	// DOS via Range
	values = []string{"bytes=cow"}
	headerDOSTemplate(&result, values, "Range", "", true)

	// DOS via X-Forwarded-Protocol
	values = []string{"http", "https", "ssl", "nonesense"}
	headerDOSTemplate(&result, values, "X-Forwarded-Protocol", "", true)

	// DOS via X-Fordwarded-SSL
	values = []string{"on", "off", "nonsense"}
	headerDOSTemplate(&result, values, "X-Forwarded-SSL", "", true)

	return result
}

/* HTTP Header Oversize */
func hho(result *Result) {
	repetitions := []int{50, 100, 200} //4k, 8k, 16k

	msg := fmt.Sprintf("Testing now HHO with Size Limits of ~80*%d bytes\n", repetitions)
	PrintVerbose(msg, NoColor, 1)

	//c := make(chan result) //<- needed?
	sem := make(chan int, Config.Threads)
	var wg sync.WaitGroup
	wg.Add(len(repetitions))
	var m sync.Mutex

	for _, repetition := range repetitions {
		go func(repetition int) {
			defer wg.Done()
			sem <- 1

			limit := repetition * 8 / 100
			//msg := fmt.Sprintf("Testing now HHO with Size Limit %dk bytes\n", limit)
			//Print(msg, NoColor)

			urlCb, cb := addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)

			headers := []string{}
			values := []string{}

			for i := 0; i < repetition; i++ {
				headername := fmt.Sprintf("X-Oversized-Header-%d", i+1)
				value := "Big-Value-000000000000000000000000000000000000000000000000000000000000000000000000000000"
				headers = append(headers, headername)
				values = append(values, value)
			}

			identifier := fmt.Sprintf("HHO with limit of %dk bytes", limit)
			_, statusCode1, request, _, err := firstRequest(urlCb, identifier, headers, values, "", false, false)
			if err != nil {
				if err.Error() != "stop" {
					m.Lock()
					result.HasError = true
					result.ErrorMessages = append(result.ErrorMessages, err.Error())
					m.Unlock()
				}
				return
			}

			_, statusCode2, respHeader, err := secondRequest(urlCb, identifier)
			if err != nil {
				if err.Error() != "stop" {
					m.Lock()
					result.HasError = true
					result.ErrorMessages = append(result.ErrorMessages, err.Error())
					m.Unlock()
				}
				return
			}

			msg = fmt.Sprintf("------- HHO DOS was successfully poisoned!!! cb: %s -------\n%s\n", cb, request.URL)
			m.Lock()
			_ = checkPoisoningIndicators(result, request, msg, "", "", statusCode1, statusCode2, respHeader, &m)
			m.Unlock()

			<-sem
		}(repetition)
	}

	wg.Wait()
}

func headerDOSTemplate(result *Result, values []string, header string, msgextra string, httpConform bool) {
	msg := fmt.Sprintf("Testing now %s DOS with header %s and values %s\n", msgextra, header, values)
	PrintVerbose(msg, NoColor, 1)

	//c := make(chan result) //<- needed?
	sem := make(chan int, Config.Threads)
	var wg sync.WaitGroup
	wg.Add(len(values))
	var m sync.Mutex

	for _, value := range values {

		go func(value string, httpConform bool) {
			defer wg.Done()
			sem <- 1

			msg := fmt.Sprintf("Testing now %s Header DOS with %s\n", header, value)
			Print(msg, NoColor)
			urlCb, cb := addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)
			success := fmt.Sprintf("------- %sDOS with header %s and value %s was poisoned!!! cb: %s -------\n", msgextra, header, value, cb)
			identifier := fmt.Sprintf("%s%s with %s", msgextra, header, value)

			rp := requestParams{
				result:           result,
				headers:          []string{header},
				values:           []string{value},
				identifier:       identifier,
				poison:           "",
				url:              urlCb,
				cb:               cb,
				success:          success,
				bodyString:       "",
				forcePost:        false,
				duplicateHeaders: false,
				m:                &m,
				cookie:           oldCookie{},
			}
			responseSplitting, _ := issueRequest(rp)

			// check for response splitting, if poison was reflected in a header
			if responseSplitting {
				msg := fmt.Sprintf("Testing now %s Header DOS with %s\n", header, value)
				Print(msg, NoColor)

				rp.values[0] += getRespSplit()
				rp.url, rp.cb = addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)
				rp.success = fmt.Sprintf("------- %sDOS with header %s and value %s was poisoned with response splitting!!! cb: %s -------\n", msgextra, header, rp.values[0], rp.cb)
				rp.identifier += getRespSplit() + " with response splitting"

				issueRequest(rp)
			}

			<-sem
		}(value, httpConform)
	}
	wg.Wait()
}

func ScanCSS() Result {
	var result Result
	result.Technique = "CSS poisoning"

	bodyReader := strings.NewReader(Config.Website.Body)
	tokenizer := html.NewTokenizer(bodyReader)

	var urls []string

	eof := false
	for !eof {
		tokentype := tokenizer.Next()

		switch {
		case tokentype == html.StartTagToken:

			token := tokenizer.Token()

			if token.Data == "link" {
				for _, a := range token.Attr {
					if a.Key == "href" {
						tempURL := addDomain(a.Val, Config.Website.Domain)
						if tempURL != "" {
							urls = append(urls, tempURL)
						}
						break
					}
				}
			}
		// When EOF is reached a html.ErrorToken appears
		case tokentype == html.ErrorToken:
			err := tokenizer.Err()
			if err == io.EOF {
				eof = true
				break
			}
			msg := fmt.Sprintf("error tokenizing HTML: %v", tokenizer.Err())
			Print(msg, Yellow)
		}
	}

	if len(urls) == 0 {
		msg := "No CSS files were found.\n"
		PrintVerbose(msg, Yellow, 1)

		return result
	}
	msg := fmt.Sprintf("Testing the following CSS files for poisoning\n%s\n", urls)
	PrintVerbose(msg, NoColor, 1)

	//c := make(chan result) //<- needed?
	sem := make(chan int, Config.Threads)
	var wg sync.WaitGroup
	wg.Add(len(urls))
	var m sync.Mutex

	for _, url := range urls {

		go func(url string) {
			defer wg.Done()
			sem <- 1

			//msg := fmt.Sprintf("Testing now %s Header DOS with %s\n", header, value)
			//Print(msg, NoColor)

			urlCb, cb := addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)

			identifier := url
			_, _, request, _, err := firstRequest(urlCb, identifier, []string{""}, []string{""}, "", false, false)
			if err != nil {
				if err.Error() != "stop" {
					m.Lock()
					result.HasError = true
					result.ErrorMessages = append(result.ErrorMessages, err.Error())
					m.Unlock()
				}
				<-sem
				return
			}

			body, _, _, err := secondRequest(url, identifier)
			if err != nil {
				if err.Error() != "stop" {
					m.Lock()
					result.HasError = true
					result.ErrorMessages = append(result.ErrorMessages, err.Error())
					m.Unlock()
				}
				<-sem
				return
			}

			if strings.Contains(string(body), cb) {
				msg = fmt.Sprintf("------- A CSS file was poisoned!!! cb: %s -------\n%s\n", cb, request.URL)
				Print(msg, Green)
				msg = "Reason: CSS reflects URL\n"
				Print(msg, Green)

				m.Lock()
				result.Vulnerable = true
				result.Requests = append(result.Requests, request)
				m.Unlock()
			}

			<-sem
		}(url)

	}
	wg.Wait()

	return result
}
