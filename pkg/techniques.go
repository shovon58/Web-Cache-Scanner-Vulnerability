package pkg

import (
	"bufio"
	"crypto/x509"
	"fmt"
	"io"
	"net"
	"net/http"
	"strings"
	"sync"
	"time"

	"golang.org/x/net/html"
)

var impactfulQueries []string
var responseSplittingHeader string
var responseSplittingValue string

func init() {
	responseSplittingHeader = "Web_Cache"
	responseSplittingValue = "Vulnerability_Scanner"
}

func returnResponseSplitting() string {
	return "\r\n" + responseSplittingHeader + ": " + responseSplittingValue
}

/* Scan cookies for poisoning */
func ScanCookies() Result {
	var result Result
	result.Technique = "Cookies"
	for i := 0; i < len(Config.Website.Cookies); i++ {
		poison := randInt()
		msg := fmt.Sprintf("Checking cookie %s\n", Config.Website.Cookies[i].Name)
		Print(msg, NoColor)

		urlCb, cb := addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)

		identifier := Config.Website.Cookies[i].String() + "=" + Config.Website.Cookies[i].Value

		msg = fmt.Sprintf("Overwriting %s=%s with %s=%s\n", Config.Website.Cookies[i].Name, Config.Website.Cookies[i].Value, Config.Website.Cookies[i].Name, poison)
		Print(msg, NoColor)
		oldValue := Config.Website.Cookies[i].Value
		Config.Website.Cookies[i].Value = poison

		_, statusCode1, request, _, timeOut1, err := firstRequest(urlCb, identifier, []string{}, []string{}, "", false, false)
		if err != nil && !timeOut1 {
			if err.Error() != "stop" {
				result.HasError = true
				result.ErrorMessage += err.Error()
			}
			return result
		}
		Config.Website.Cookies[i].Value = oldValue
		body, statusCode2, respHeader, timeOut2, err := secondRequest(urlCb, identifier)

		if err != nil && !timeOut2 {
			if err.Error() != "stop" {
				result.HasError = true
				result.ErrorMessage += err.Error()
			}
			return result
		}
		msg = fmt.Sprintf("------- Cookie %s was successfully poisoned!!! cb: %s poison: %s -------\n%s\n", Config.Website.Cookies[i].Name, cb, poison, request.URL)
		result = checkPoisoningIndicators(result, request, msg, string(body), poison, statusCode1, statusCode2, respHeader, timeOut1 && timeOut2)

		//var responseSplittingBool bool

		// gleiche wie oben nur mit anderem poison wert
		/*if responseSplittingBool {

		}*/
	}
	return result
}

func ScanForwardingHeaders() Result {
	var result Result
	result.Technique = "Forward/Host Headers"

	// Host header
	header := "Host"
	values := []string{":31337", ":@31337", " 31337"}
	for _, value := range values {
		result = ForwardHeadersTemplate(result, []string{header}, []string{value}, header, value, false)
	}

	// Duplicate Host header
	header = "host"
	poison := randInt()
	values = []string{poison}
	for _, value := range values {
		result = ForwardHeadersTemplate(result, []string{header}, []string{value}, header, value, true)
	}

	// X-Forwarded Headers
	headers := []string{"X-Forwarded-Host", "X-Forwarded-Scheme"}
	poison = randInt()
	values = []string{poison, "nothttps"}
	identifier := "X-Forwarded-Host and X-Forwarded-Scheme"
	result = ForwardHeadersTemplate(result, headers, values, identifier, poison, false)

	// Forwarded Header
	header = "Forwarded"
	value := "host=" + randInt()
	result = ForwardHeadersTemplate(result, []string{header}, []string{value}, header, value, false)

	// X-Forwarded-Port Header
	header = "X-Forwarded-Port"
	value = "31337"
	result = ForwardHeadersTemplate(result, []string{header}, []string{value}, header, value, false)

	return result
}

func ForwardHeadersTemplate(result Result, headers []string, values []string, identifier string, poison string, duplicateHeaders bool) Result {
	urlCb, cb := addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)

	_, statusCode1, request, _, timeOut1, err := firstRequest(urlCb, identifier, headers, values, "", false, duplicateHeaders)
	if err != nil && !timeOut1 {
		if err.Error() != "stop" {
			result.HasError = true
			result.ErrorMessage += err.Error()
		}
		return result
	}
	//TODO: Check first request, if second is necessary?
	body, statusCode2, respHeader, timeOut2, err := secondRequest(urlCb, identifier)

	if err != nil && !timeOut2 {
		if err.Error() != "stop" {
			result.HasError = true
			result.ErrorMessage += err.Error()
		}
		return result
	}
	msg := fmt.Sprintf("------- %s was successfully poisoned!!! cb: %s poison: %s -------\n%s\n", headers, cb, values, request.URL)
	result = checkPoisoningIndicators(result, request, msg, string(body), poison, statusCode1, statusCode2, respHeader, timeOut1 && timeOut2)

	return result
}

func ScanHTTPResponseSplitting() Result {
	var result Result
	identifier := "HTTP Response Splitting"
	result.Technique = identifier
	return result
}

func ScanHTTPRequestSmuggling(caCertPool *x509.CertPool) Result {
	var result Result
	identifier := "HTTP Request Smuggling"
	result.Technique = identifier

	/*
		dialer, err := proxy.SOCKS5("tcp", strings.TrimPrefix(Config.ProxyURL, "http://"), nil, nil)
		if err != nil {
			PrintFatal(err.Error())
		}
		Print("ads", NoColor)*/
	/*conn, err := tls.Dial("tcp", "www.google.com:80", &tls.Config{
		RootCAs:            caCertPool,
		ServerName:         "127.0.0.1:8080",
		InsecureSkipVerify: true,
	})*/
	address := strings.TrimPrefix(Config.Website.Domain, "http")
	address = strings.TrimPrefix(address, "s")
	address = strings.TrimPrefix(address, "://")
	address = strings.TrimSuffix(address, "/")

	dialer := net.Dialer{Timeout: time.Duration(Config.TimeOut) * time.Second}

	headers := generateHeaderString()

	req := CLTE(headers)
	for i := 0; i < 3; i++ {
		conn, err := dialer.Dial("tcp", address+":80")
		if err != nil {
			PrintFatal(err.Error())
		}
		defer conn.Close()

		fmt.Fprint(conn, req)

		//Unterer Teil... Wenn Timeout zÃ¤hler hoch. Bei 3 mal timeout hat es geklappt. Zwischendurch vllt ein normales request, was nicht timeouten darf
		// Das hier als FUnktion machen. Mit anderen Techniken TECL,CLCL... diese Funktion einfach mit einem anderen req string aufrufen

		resp, err := bufio.NewReader(conn).ReadString('\n')
		if err != nil {
			msg := "Smuggling: " + err.Error() + "\n"
			Print(msg, Yellow)
			result.HasError = true
			result.ErrorMessage = msg
			return result
		}
		Print(resp, NoColor)
	}

	return result
	/*
		urlCb, cb := addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)
		urlCbPoison, cbPoison := addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)
		urlCbToPoison, _ := addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)

		bodyVal := fmt.Sprintf("GET %s HTTP/1.1\r\n"+
			"Host: %s\r\n"+
			"HeaderWithSpace: "+
			"GET %s HTTP/1.1\r\n"+
			"Host: %s\r\n"+
			"\r\n", urlCbPoison, Config.Website.BaseUrlStr, urlCbToPoison, Config.Website.BaseUrlStr)

		//lowercase header only works with HTTP1
		headers := []string{"content-length", "coNtent-length"}
		values := []string{"0", "11"}

		forcePost, duplicateHeaders := true, true
		_, statusCode1, request, _, timeOut1, err := firstRequest(urlCb, identifier, headers, values, bodyVal, forcePost, duplicateHeaders)
		if err != nil && !timeOut1 {
			if err.Error() != "stop" {
				result.HasError = true
				result.ErrorMessage += err.Error()
			}
			return result
		}

		body, statusCode2, respHeader, timeOut2, err := secondRequest(urlCb, identifier)

		if err != nil && !timeOut2 {
			if err.Error() != "stop" {
				result.HasError = true
				result.ErrorMessage += err.Error()
			}
			return result
		}
		msg := fmt.Sprintf("------- %s was successfully poisoned!!! cb: %s -------\n%s\n", identifier, cb, request.URL)
		result = checkPoisoningIndicators(result, request, msg, string(body), cbPoison, statusCode1, statusCode2, respHeader, timeOut1 && timeOut2)
	*/
}

/* Scan headers for poisoning */
func ScanHeaders(headerList []string) Result {
	var result Result
	result.Technique = "Headers"

	//c := make(chan result) //<- needed?
	sem := make(chan int, Config.Threads)
	var wg sync.WaitGroup
	wg.Add(len(headerList))
	var m sync.Mutex

	for i, header := range headerList {
		header = strings.Trim(header, "\r")
		if header == "" {
			msg := fmt.Sprintf("Skipping empty header (%d/%d)\n", i+1, len(headerList))
			PrintVerbose(msg, NoColor, 1)

			wg.Done()
			continue
		}

		header = http.CanonicalHeaderKey(header)

		poison := randInt()

		go func(i int, header string, poison string) {
			defer wg.Done()
			sem <- 1

			msg := fmt.Sprintf("Testing now (%d/%d) %s\n", i+1, len(headerList), header)
			PrintVerbose(msg, NoColor, 2)

			urlCb, cb := addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)
			identifier := fmt.Sprintf("header %s", header)
			_, statusCode1, request, _, timeOut1, err := firstRequest(urlCb, identifier, []string{header}, []string{poison}, "", false, false)
			if err != nil && !timeOut1 {
				if err.Error() != "stop" {
					m.Lock()
					result.HasError = true
					result.ErrorMessage += err.Error()
					m.Unlock()
				}
				<-sem
				return
			}

			//TODO: Check first request, if second is necessary?
			body, statusCode2, respHeader, timeOut2, err := secondRequest(urlCb, identifier)
			if err != nil && !timeOut2 {
				if err.Error() != "stop" {
					m.Lock()
					result.HasError = true
					result.ErrorMessage += err.Error()
					m.Unlock()
				}
				<-sem
				return
			}

			msg = fmt.Sprintf("------- Header %s was successfully poisoned!!! cb: %s poison: %s -------\n%s\n", header, cb, poison, request.URL)
			m.Lock()
			result = checkPoisoningIndicators(result, request, msg, string(body), poison, statusCode1, statusCode2, respHeader, timeOut1 && timeOut2)
			m.Unlock()

			<-sem
		}(i, header, poison)

	}
	wg.Wait()

	return result
}

/* Scan query parameters for poisoning */
func ScanParameters(parameterList []string) Result {
	var result Result
	result.Technique = "Parameters"

	//c := make(chan result) //<- needed?
	sem := make(chan int, Config.Threads)
	var wg sync.WaitGroup
	wg.Add(len(parameterList))
	var m sync.Mutex

	impactfulQueries = nil

	for i, parameter := range parameterList {
		if parameter == "" {
			msg := fmt.Sprintf("Skipping empty query (%d/%d) %s\n", i+1, len(parameterList), parameter)
			PrintVerbose(msg, NoColor, 2)
			wg.Done()
			continue
		}

		poison := randInt()

		go func(i int, parameter string, poison string) {
			defer wg.Done()
			sem <- 1

			parameter = strings.Trim(parameter, "\r")

			msg := fmt.Sprintf("Testing now Parameter (%d/%d) %s\n", i+1, len(parameterList), parameter)
			PrintVerbose(msg, NoColor, 2)

			var urlCb, cb string
			if _, ok := Config.Website.Queries[parameter]; ok {
				// if the query to add is already present
				queryParameterMap := make(map[string]string)

				for key, val := range Config.Website.Queries {
					queryParameterMap[key] = val
				}

				msg := fmt.Sprintf("Overwriting %s=%s with %s=%s\n", parameter, queryParameterMap[parameter], parameter, poison)
				Print(msg, NoColor)
				queryParameterMap[parameter] = poison

				urlCb = Config.Website.BaseUrlStr + "?"
				for key, val := range queryParameterMap {
					if !strings.HasSuffix(urlCb, "?") {
						urlCb += "&"
					}
					urlCb += key + "=" + val
				}

				urlCb, cb = addCacheBuster(urlCb+Config.QuerySeperator, "", Config.CacheBuster)
			} else {
				// if query isn't already present, just add it and the cachebuster
				urlCb = Config.Website.Url.String()
				urlCb += parameter + "=" + poison + Config.QuerySeperator
				urlCb, cb = addCacheBuster(urlCb, "", Config.CacheBuster)
			}

			identifier := fmt.Sprintf("parameter %s", parameter)
			_, statusCode1, request, _, timeOut1, err := firstRequest(urlCb, identifier, []string{""}, []string{poison}, "", false, false)
			if err != nil && !timeOut1 {
				if err.Error() != "stop" {
					m.Lock()
					result.HasError = true
					result.ErrorMessage += err.Error()
					m.Unlock()
				}
				<-sem
				return
			}

			impactfulQueries = append(impactfulQueries, parameter)

			// get urlCb with the cachebuster but without the poisoned query
			urlCb, cb = addCacheBuster(Config.Website.Url.String(), cb, Config.CacheBuster)

			body, statusCode2, respHeader, timeOut2, err := secondRequest(urlCb, identifier)
			if err != nil && !timeOut2 {
				if err.Error() != "stop" {
					m.Lock()
					result.HasError = true
					result.ErrorMessage += err.Error()
					m.Unlock()
				}
				<-sem
				return
			}

			msg = fmt.Sprintf("------- Query Parameter %s was successfully poisoned!!! cb: %s poison: %s -------\n%s\n", parameter, cb, poison, request.URL)
			m.Lock()
			result = checkPoisoningIndicators(result, request, msg, string(body), poison, statusCode1, statusCode2, respHeader, timeOut1 && timeOut2)
			m.Unlock()

			<-sem
		}(i, parameter, poison)

	}
	wg.Wait()

	return result
}

/* Check for fat GET */
func ScanFatGET() Result {
	var result Result
	result.Technique = "Fat GET"

	if len(impactfulQueries) == 0 {
		errMsg := "No impactful query parameters were found beforehand. Run the query parameter scan (maybe with a different wordlist)."
		Print(errMsg+"\n", Yellow)
		result.HasError = true
		result.ErrorMessage = errMsg
		return result
	} else {
		msg := fmt.Sprintf("The following parameters were found to be impactful and will be tested for parameter cloaking: %s\n", impactfulQueries)
		Print(msg, NoColor)
	}

	//c := make(chan result) //<- needed?
	sem := make(chan int, Config.Threads)
	var wg sync.WaitGroup
	wg.Add(len(impactfulQueries))
	var m sync.Mutex

	headers := []string{"", "", "X-HTTP-Method-Override", "X-HTTP-Method", "X-Method-Override"}
	values := []string{"", "", "POST", "POST", "POST"}

	for method := 0; method < 5; method++ {
		var identifier string
		forcePost := false
		if method == 0 {
			identifier = "simple Fat GET"
		} else if method == 1 {
			identifier = "POST Fat GET"
			forcePost = true
		} else {
			identifier = fmt.Sprintf("%s Fat GET", headers[method-2])
		}
		msg := "Testing now " + identifier + "\n"
		Print(msg, NoColor)

		for i, s := range impactfulQueries {

			poison := randInt()

			// basic fat get technique
			go func(i int, s string, poison string) {
				defer wg.Done()
				sem <- 1

				msg := fmt.Sprintf("(%d/%d) %s\n", i+1, len(impactfulQueries), s)
				PrintVerbose(msg, NoColor, 2)

				urlCb, cb := addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)

				bodyString := s + "=" + poison
				_, statusCode1, request, _, timeOut1, err := firstRequest(urlCb, identifier, []string{headers[method]}, []string{values[method]}, bodyString, forcePost, false)

				if err != nil && !timeOut1 {
					if err.Error() != "stop" {
						m.Lock()
						result.HasError = true
						result.ErrorMessage += err.Error()
						m.Unlock()
					}
					<-sem
					return
				}

				body, statusCode2, respHeader, timeOut2, err := secondRequest(urlCb, identifier)
				if err != nil && !timeOut2 {
					if err.Error() != "stop" {
						m.Lock()
						result.HasError = true
						result.ErrorMessage += err.Error()
						m.Unlock()
					}
					<-sem
					return
				}

				msg = fmt.Sprintf("------- Query Parameter %s was successfully poisoned via %s!!! cb: %s poison:%s -------\n%s\n", s, identifier, cb, poison, request.URL)
				m.Lock()
				result = checkPoisoningIndicators(result, request, msg, string(body), poison, statusCode1, statusCode2, respHeader, timeOut1 && timeOut2)
				m.Unlock()

				<-sem
			}(i, s, poison)
		}
		wg.Wait()
		wg.Add(len(impactfulQueries))
	}

	return result
}

/* Check for Parameter Cloaking */
func ScanParameterCloaking() Result {
	var result Result
	result.Technique = "Parameter Cloaking"

	if len(impactfulQueries) == 0 {
		errMsg := "No impactful query parameters were found beforehand. Run the query parameter scan (maybe with a different wordlist)."
		Print(errMsg+"\n", Yellow)
		result.HasError = true
		result.ErrorMessage = errMsg
		return result
	} else {
		msg := fmt.Sprintf("The following parameters were found to be impactful and will be tested for parameter cloaking:\n%s\n", impactfulQueries)
		Print(msg, NoColor)
	}

	utm_parameter := []string{"utm_source", "utm_medium", "utm_campaign", "utm_content", "utm_term"}
	unkeyed_parameter := []string{}

	urlCb, _ := addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)

	/***********Check if urlCb already contains utm parameter.
				Check if ? or querySeperator is needed
	****************/

	// The first request is made so a cache miss is forced and the following responses will only
	//have a cache hit, if they are unkeyed

	identifier := "first request %s"
	firstRequest(urlCb, identifier, []string{""}, []string{""}, "", false, false)

	sem := make(chan int, Config.Threads)
	var wg sync.WaitGroup
	var m sync.Mutex

	if Config.Website.Cache.Indicator == "" {
		//Cant test if utm_parameter are unkeyed if X-Cache isn't set
		//So they will be all added as unkeyed_parameter
		msg := "hit/miss isn't verbose. Can't check which utm_parameter is unkeyed, so all will be used\n"
		Print(msg, Yellow)
		unkeyed_parameter = utm_parameter
	} else {
		//Test which utm_parameter are unkeyed
		//c := make(chan result) //<- needed?

		wg.Add(len(utm_parameter))

		for i, s := range utm_parameter {
			go func(i int, s string) {
				defer wg.Done()
				sem <- 1

				msg := fmt.Sprintf("Testing now for unkeyed utm parameters (%d/%d) %s\n", i+1, len(utm_parameter), s)
				PrintVerbose(msg, NoColor, 2)

				// add utm parameter after cachebuster. give utm parameter nonsense value
				urlPoisoned := urlCb + Config.QuerySeperator + s + "=foobar"
				identifier := fmt.Sprintf("unkeyed utm %s", s)
				//TODO: TimeOut behandeln!!!
				_, _, _, respHeader, _, err := firstRequest(urlPoisoned, identifier, []string{""}, []string{""}, "", false, false)
				if err == nil && respHeader != nil && strings.Contains(strings.ToLower(respHeader.Get(Config.Website.Cache.Indicator)), "hit") {
					m.Lock()
					unkeyed_parameter = append(unkeyed_parameter, s)
					m.Unlock()
				} else if err != nil && err.Error() != "stop" {
					m.Lock()
					result.HasError = true
					result.ErrorMessage += err.Error()
					m.Unlock()
				}
			}(i, s)
		}
		wg.Wait()
	}

	if len(unkeyed_parameter) == 0 {
		msg := "No unkeyed utm parameters could be found. Parameter Cloaking is not possible using utm parameters\n"
		Print(msg, Yellow)
	} else {
		msg := fmt.Sprintf("The following utm parameters were found to be unkeyed and will be tested for parameter cloaking:\n %s\n", unkeyed_parameter)
		Print(msg, NoColor)
	}

	cloak := ";"
	if Config.QuerySeperator == ";" {
		cloak = "&"
	}

	for iu, u := range unkeyed_parameter {

		//test one unkeyed parameter with all impactfulQueries one after another
		wg.Add(len(impactfulQueries))

		for is, s := range impactfulQueries {

			poison := randInt()

			go func(iu int, u string, is int, s string, poison string) {
				defer wg.Done()
				sem <- 1

				msg := fmt.Sprintf("Testing now Parameter Cloaking (%d/%d) %s%s%s\n", iu+is+1, len(impactfulQueries)*len(unkeyed_parameter), u, cloak, s)
				PrintVerbose(msg, NoColor, 2)

				urlCb, cb := addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)
				urlPoisoned := urlCb + Config.QuerySeperator + u + "=foobar" + cloak + s + "=" + poison

				identifier := fmt.Sprintf("parameter cloaking %s %s", u, s)
				_, statusCode1, request, _, timeOut1, err := firstRequest(urlPoisoned, identifier, []string{""}, []string{poison}, "", false, false)
				if err != nil && !timeOut1 {
					if err.Error() != "stop" {
						m.Lock()
						result.HasError = true
						result.ErrorMessage += err.Error()
						m.Unlock()
					}
					<-sem
					return
				}

				body, statusCode2, respHeader, timeOut2, err := secondRequest(urlCb, identifier)
				if err != nil && !timeOut2 {
					if err.Error() != "stop" {
						m.Lock()
						result.HasError = true
						result.ErrorMessage += err.Error()
						m.Unlock()
					}
					<-sem
					return
				}

				msg = fmt.Sprintf("------- Query Parameter %s was successfully poisoned via Parameter Cloaking using %s!!! cb:%s poison:%s -------\n%s\n", s, u, cb, poison, request.URL)
				m.Lock()
				result = checkPoisoningIndicators(result, request, msg, string(body), poison, statusCode1, statusCode2, respHeader, timeOut1 && timeOut2)
				m.Unlock()

				<-sem
			}(iu, u, is, s, poison)
		}
		wg.Wait()
	}

	return result
}

/* Check for different DOS techniques */
func DOS() Result {
	var result Result
	result.Technique = "DOS"

	// TODO: Ist nur Header Value oder auch Header Name ausschlaggebend?
	result = hho(result)

	// TODO: Check for more META CHARACTERS?
	result = hmc(result)

	// TODO: Add more HEADERS/METHODS?
	result = hmo(result)

	// DOS via not implemented transferEncoding
	values := []string{"asdf"}
	result = headerDOSTemplate(result, values, "zTRANSFER-ENCODING", "Not supported Transfer-Encoding ", true)
	// DOS via incompatible/outdated browser agent
	// TODO: Add more USERAGENTS?
	values = []string{"Mozilla/5.0 (Windows; U; MSIE 9.0; WIndows NT 9.0; en-US))"}
	result = headerDOSTemplate(result, values, "User-Agent", "incompatible browser ", true)
	// DOS via Max-Forwards (Webserver/Cache returns request)
	values = []string{"0", "1", "2"}
	result = headerDOSTemplate(result, values, "Max-Forwards", "", true)
	// DOS via waf blocking because of a blacklist word
	// TODO: change header to probably whitelisted header, More Blacklist words?
	values = []string{".burpcollaborator.net", "<script>alert(1)</script>"}
	result = headerDOSTemplate(result, values, "Any-Header", "blacklist ", true)
	// DOS via Range
	values = []string{"bytes=cow"}
	result = headerDOSTemplate(result, values, "Range", "", true)
	// DOS via X-Forwarded-Protocol
	values = []string{"http", "https", "ssl", "nonesense"}
	result = headerDOSTemplate(result, values, "X-Forwarded-Protocol", "", true)
	// DOS via X-Fordwarded-SSL
	values = []string{"on", "off", "nonsense"}
	result = headerDOSTemplate(result, values, "X-Forwarded-SSL", "", true)

	return result
}

/* HTTP Header Oversize */
func hho(result Result) Result {
	repetitions := []int{50, 100, 200} //4k, 8k, 16k

	msg := fmt.Sprintf("Testing now HHO with Size Limits of ~80*%d bytes\n", repetitions)
	PrintVerbose(msg, NoColor, 1)

	//c := make(chan result) //<- needed?
	sem := make(chan int, Config.Threads)
	var wg sync.WaitGroup
	wg.Add(len(repetitions))
	var m sync.Mutex

	for _, repetition := range repetitions {
		go func(repetition int) {
			defer wg.Done()
			sem <- 1

			limit := repetition * 8 / 100
			//msg := fmt.Sprintf("Testing now HHO with Size Limit %dk bytes\n", limit)
			//Print(msg, NoColor)

			urlCb, cb := addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)

			headers := []string{}
			values := []string{}

			for i := 0; i < repetition; i++ {
				headername := fmt.Sprintf("X-Oversized-Header-%d", i+1)
				value := "Big-Value-000000000000000000000000000000000000000000000000000000000000000000000000000000"
				headers = append(headers, headername)
				values = append(values, value)
			}

			identifier := fmt.Sprintf("HHO with limit of %dk bytes", limit)
			_, statusCode1, request, _, timeOut1, err := firstRequest(urlCb, identifier, headers, values, "", false, false)
			if err != nil && !timeOut1 {
				if err.Error() != "stop" {
					m.Lock()
					result.HasError = true
					result.ErrorMessage += err.Error()
					m.Unlock()
				}
				return
			}

			_, statusCode2, respHeader, timeOut2, err := secondRequest(urlCb, identifier)
			if err != nil && !timeOut2 {
				if err.Error() != "stop" {
					m.Lock()
					result.HasError = true
					result.ErrorMessage += err.Error()
					m.Unlock()
				}
				return
			}

			msg = fmt.Sprintf("------- HHO DOS was successfully poisoned!!! cb: %s -------\n%s\n", cb, request.URL)
			m.Lock()
			result = checkPoisoningIndicators(result, request, msg, "", "", statusCode1, statusCode2, respHeader, timeOut1 && timeOut2)
			m.Unlock()

			<-sem
		}(repetition)
	}

	wg.Wait()

	return result
}

/* HTTP Meta Character */
func hmc(result Result) Result {

	//TODO: Change to other header, which is probably whitelisted
	headers := []string{"X-Metachar-Header"}
	values := []string{"\\n", "\\r", "\\a", "\\0", "\\b", "\\e", "\\v", "\\f", "\\u0000"}

	for _, header := range headers {
		result = headerDOSTemplate(result, values, header, "HMC ", true)
	}

	return result
}

/* HTTP Method Override Attack */
func hmo(result Result) Result {

	values := []string{"GET", "POST", "DELETE", "NONSENSE"}
	headers := []string{"X-HTTP-Method-Override", "X-HTTP-Method", "X-Method-Override"}

	for _, header := range headers {
		result = headerDOSTemplate(result, values, header, "HMO ", true)
	}

	return result
}

func headerDOSTemplate(result Result, values []string, header string, msgextra string, httpConform bool) Result {
	msg := fmt.Sprintf("Testing now %sDOS with header %s and values %s\n", msgextra, header, values)
	PrintVerbose(msg, NoColor, 1)

	//c := make(chan result) //<- needed?
	sem := make(chan int, Config.Threads)
	var wg sync.WaitGroup
	wg.Add(len(values))
	var m sync.Mutex

	for _, value := range values {

		go func(value string, httpConform bool) {
			defer wg.Done()
			sem <- 1

			//msg := fmt.Sprintf("Testing now %s Header DOS with %s\n", header, value)
			//Print(msg, NoColor)

			urlCb, cb := addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)

			identifier := fmt.Sprintf("%s%s with %s", msgextra, header, value)
			_, statusCode1, request, _, timeOut1, err := firstRequest(urlCb, identifier, []string{header}, []string{value}, "", false, false)
			if err != nil && !timeOut1 {
				if err.Error() != "stop" {
					m.Lock()
					result.HasError = true
					result.ErrorMessage += err.Error()
					m.Unlock()
				}
				<-sem
				return
			}

			body, statusCode2, respHeader, timeOut2, err := secondRequest(urlCb, identifier)
			if err != nil && !timeOut2 {
				if err.Error() != "stop" {
					m.Lock()
					result.HasError = true
					result.ErrorMessage += err.Error()
					m.Unlock()
				}
				<-sem
				return
			}

			msg = fmt.Sprintf("------- %sDOS with header %s and value %s was poisoned!!! cb: %s -------\n%s\n", msgextra, header, value, cb, request.URL)
			m.Lock()
			result = checkPoisoningIndicators(result, request, msg, string(body), "", statusCode1, statusCode2, respHeader, timeOut1 && timeOut2)
			m.Unlock()

			<-sem
		}(value, httpConform)
	}
	wg.Wait()

	return result
}

func ScanCSS() Result {
	var result Result
	result.Technique = "CSS poisoning"

	bodyReader := strings.NewReader(Config.Website.Body)
	tokenizer := html.NewTokenizer(bodyReader)

	var urls []string

	eof := false
	for !eof {
		tokentype := tokenizer.Next()

		switch {
		case tokentype == html.StartTagToken:

			token := tokenizer.Token()

			if token.Data == "link" {
				for _, a := range token.Attr {
					if a.Key == "href" {
						tempURL := addDomain(a.Val, Config.Website.Domain)
						if tempURL != "" {
							urls = append(urls, tempURL)
						}
						break
					}
				}
			}
		// When EOF is reached a html.ErrorToken appears
		case tokentype == html.ErrorToken:
			err := tokenizer.Err()
			if err == io.EOF {
				eof = true
				break
			}
			msg := fmt.Sprintf("error tokenizing HTML: %v", tokenizer.Err())
			Print(msg, Yellow)
		}
	}

	if len(urls) == 0 {
		msg := "No CSS files were found.\n"
		PrintVerbose(msg, Yellow, 1)

		return result
	}
	msg := fmt.Sprintf("Testing the following CSS files for poisoning\n%s\n", urls)
	PrintVerbose(msg, NoColor, 1)

	//c := make(chan result) //<- needed?
	sem := make(chan int, Config.Threads)
	var wg sync.WaitGroup
	wg.Add(len(urls))
	var m sync.Mutex

	for _, url := range urls {

		go func(url string) {
			defer wg.Done()
			sem <- 1

			//msg := fmt.Sprintf("Testing now %s Header DOS with %s\n", header, value)
			//Print(msg, NoColor)

			urlCb, cb := addCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)

			identifier := url
			_, _, request, _, timeOut1, err := firstRequest(urlCb, identifier, []string{""}, []string{""}, "", false, false)
			if err != nil && !timeOut1 {
				if err.Error() != "stop" {
					m.Lock()
					result.HasError = true
					result.ErrorMessage += err.Error()
					m.Unlock()
				}
				<-sem
				return
			}

			body, _, _, timeOut2, err := secondRequest(url, identifier)
			if err != nil && !timeOut2 {
				if err.Error() != "stop" {
					m.Lock()
					result.HasError = true
					result.ErrorMessage += err.Error()
					m.Unlock()
				}
				<-sem
				return
			}

			if strings.Contains(string(body), cb) {
				msg = fmt.Sprintf("------- A CSS file was poisoned!!! cb: %s -------\n%s\n", cb, request.URL)
				Print(msg, Green)
				msg = "Reason: CSS reflects URL\n"
				Print(msg, Green)

				m.Lock()
				result.Vulnerable = true
				result.Requests = append(result.Requests, request)
				m.Unlock()
			}

			<-sem
		}(url)

	}
	wg.Wait()

	return result
}
