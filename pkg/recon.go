package pkg

import (
	"bytes"
	"fmt"
	"io/ioutil"
	"log"
	"net/http"
	"net/url"
	"os"
	"strings"
)

func init() {

}

func CheckCache(client http.Client, config Config) Cache {
	/*
		Wie kann ich erkennen, dass ein Cache aktiv ist?
		- X-Cache : hit / miss
		- Zeit messen
	*/
	/*
		Was kann ich als Cache Buster benutzen?
		- Query-Parameter (cachebuster)
		- Header (z.B. origin)
	*/
	var cache Cache

	for key, val := range config.Website.Headers {
		switch strings.ToLower(key) {
		case "cache-control":
			for _, val2 := range val {
				switch strings.ToLower(val2) {
				case "no-cache":
					fmt.Println("Cache-Control is set to no-cache, so the site can't be tested for web cache poisoning")
					if config.Force == false {
						cache.NoCache = true
						return cache
					}
				case "no-store":
					fmt.Println("Cache-Control is set to no-store, so the site can't be tested for web cache poisoning")
					if config.Force == false {
						cache.NoCache = true
						return cache
					}
				case "only-if-cached":
					fmt.Println("Cache-Control is set to only-if-cached, so testing for web cache poisoning may not be possible")
				}
			}
		case "x-cache":
			cache.XCache = true
		}
	}

	if cache.XCache {
		fmt.Println("The x-cache header was found. Now the cachebuster will be tried.")
	} else {
		log.Println("The x-cache header wasn't found")
		if config.Force == false {
			os.Exit(1)
		}
	}

	urlCb, _ := addCacheBuster(config.Website.Url.String(), "", config.CacheBuster)

	var req *http.Request
	var err error
	if config.DoPost {
		req, err = http.NewRequest("POST", urlCb, bytes.NewBufferString(config.Body))
	} else {
		req, err = http.NewRequest("GET", urlCb, nil)
	}
	if err != nil {
		log.Fatalln(err)
	}

	setRequest(req, config.DoPost, config)

	resp, err := client.Do(req)
	if err != nil {
		log.Fatalln(err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != config.Website.StatusCode {
		log.Printf("Unexpected Status Code %d\n", resp.StatusCode)
	}

	if resp.Header.Get("x-cache") == "hit" {
		cache.Parameter = false
		log.Printf("Parameter %s as CacheBuster is not possible\n", config.CacheBuster)
	}

	urlCb, _ = addCacheBuster(config.Website.Url.String(), "", config.CacheBuster)

	if config.DoPost {
		req, err = http.NewRequest("POST", urlCb, bytes.NewBufferString(config.Body))
	} else {
		req, err = http.NewRequest("GET", urlCb, nil)
	}
	if err != nil {
		log.Fatalln(err)
	}

	setRequest(req, config.DoPost, config)
	resp, err = client.Do(req)
	if err != nil {
		log.Fatalln(err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != config.Website.StatusCode {
		log.Printf("Unexpected Status Code %d\n", resp.StatusCode)
	}

	if resp.Header.Get("x-cache") == "hit" {
		cache.Parameter = false
		log.Printf("Parameter %s as CacheBuster is not possible\n", config.CacheBuster)
	} else {
		cache.Parameter = true
		cache.ParameterName = config.CacheBuster
		log.Printf("Parameter %s as CacheBuster was successful\n", config.CacheBuster)
	}

	if cache.Parameter == false {
		log.Fatalln("Please specify a cachebuster parameter or header which works")
	}

	return cache
}

/* Simple get request to get the body of a normal response and the cookies */
func GetWebsite(requrl string, client http.Client, retrieveCookies bool, firstRequest bool, config Config) Website {

	var cache Cache

	queryParameterMap := make(map[string]string)

	// get domain
	domainParts := strings.SplitN(requrl, "/", 4)
	domain := domainParts[0] + "//" + domainParts[2]

	// splitting url like {https://www.m10x.de/}?{name=max&role=admin}
	urlSlice := strings.SplitN(requrl, "?", 2)

	// splitting queries like {name=max}&{role=admin}
	var parameterSlice []string
	if strings.Contains(requrl, "?") {
		parameterSlice = strings.Split(urlSlice[1], config.QuerySeperator)
	}

	if len(parameterSlice) > 0 {
		queryParameterMap = setQueryParameterMap(queryParameterMap, parameterSlice)
	}

	if len(config.Parameters) > 0 {
		queryParameterMap = setQueryParameterMap(queryParameterMap, config.Parameters)
	}

	requrl = urlSlice[0] + "?"
	urlNoQueries := urlSlice[0]

	// adding query parameter
	for key, val := range queryParameterMap {
		if !strings.HasSuffix(requrl, "?") {
			requrl += "&"
		}
		requrl += key + "=" + val
	}

	if len(queryParameterMap) > 0 {
		requrl += config.QuerySeperator
	}

	// adding cachebuster
	//requrlcb, _ := addCacheBuster(requrl, "", config.CacheBuster)

	var req *http.Request
	var err error
	if config.DoPost {
		req, err = http.NewRequest("POST", requrl[:(len(requrl)-1)], bytes.NewBufferString(config.Body))
	} else {
		req, err = http.NewRequest("GET", requrl[:(len(requrl)-1)], nil)
	}
	if err != nil {
		log.Fatalln(err)
	}

	setRequest(req, config.DoPost, config)
	resp, err := client.Do(req)
	if err != nil {
		log.Fatalln(err)
	}

	defer resp.Body.Close()

	body, err := ioutil.ReadAll(resp.Body)
	if err != nil {
		log.Fatalln(err)
	}

	weburl, err := url.Parse(requrl)
	if err != nil {
		log.Fatalln(err)
	}

	tempStatusCode := config.StatusCode
	if tempStatusCode == 0 {
		tempStatusCode = resp.StatusCode

		log.Printf("The default Status Code was set to %d\n", tempStatusCode)
	}

	// if retrieveCookies is false, only the specified cookies will be used
	// otherwise the by the server given cookies AND the specified cookies will be used
	cookiesWebsite := config.Website.Cookies
	if retrieveCookies {
		cookiesWebsite = append(cookiesWebsite, resp.Cookies()...)
	}

	c := Website{
		Headers:    resp.Header,
		Body:       string(body),
		Cookies:    cookiesWebsite,
		StatusCode: tempStatusCode,
		Url:        weburl,
		BaseUrlStr: urlNoQueries,
		Queries:    queryParameterMap,
		Cache:      cache,
		Domain:     domain,
		Visited:    make(map[string]bool),
	}

	return c
}

func setQueryParameterMap(queryParameterMap map[string]string, querySlice []string) map[string]string {
	for _, q := range querySlice {
		q = strings.TrimSuffix(q, "\r")
		q = strings.TrimSpace(q)
		if q == "" {
			continue
		} else if !strings.Contains(q, "=") {
			log.Printf("Specified parameter %s doesn't contain a = and will be skipped\n", q)
			continue
		} else {
			query := strings.SplitN(q, "=", 2)
			// ok is true, if a query already is set
			val, ok := queryParameterMap[query[0]]
			if ok {
				log.Printf("Overwriting %s=%s with %s=%s\n", query[0], val, query[0], query[1])
			}
			queryParameterMap[query[0]] = query[1]
		}
	}

	return queryParameterMap
}

func getSliceBetweenStrings(start string, end string, all string, trim bool) []string {
	startSlice := strings.Split(all, start)
	var betweenSlice []string

	for _, s := range startSlice {
		if strings.Contains(s, end) {
			tempSlice := strings.SplitN(s, end, 2)
			tempString := tempSlice[0]
			if trim {
				tempString = strings.TrimSpace(tempString)
				tempString = strings.Trim(tempString, "\"")
				tempString = strings.Trim(tempString, "'")
			}
			betweenSlice = append(betweenSlice, tempString)
		}
	}

	return betweenSlice
}

func CheckLinkedUrls(config Config) []string {

	aSlice := getSliceBetweenStrings("<a ", "</a>", config.Website.Body, false)
	var hrefSlice []string
	for _, a := range aSlice {
		tempSlice := getSliceBetweenStrings("href=", ">", a, true)
		hrefSlice = append(hrefSlice, tempSlice...)
	}

	log.Println(hrefSlice)

	scriptSlice := getSliceBetweenStrings("<script ", "</script>", config.Website.Body, false)
	var srcSlice []string
	for _, script := range scriptSlice {
		tempSlice := getSliceBetweenStrings("src=", ">", script, true)
		srcSlice = append(srcSlice, tempSlice...)
	}

	log.Fatalln(srcSlice)

	/*aSlice := strings.Split(config.Website.Body, "<a")
	var hrefSlice []string
	for _, href := range aSlice {

	}
	srcs := strings.Split(config.Website.Body, " src=")

	var urls []string

	for i, x := range append(hrefs, srcs...) {
		if i == 0 {
			continue
		}
		prefix := " "
		if strings.HasPrefix(x, "'") {
			x = strings.TrimPrefix(x, "'")
			prefix = "'"
		}
		if strings.HasPrefix(x, "\"") {
			x = strings.TrimPrefix(x, "\"")
			prefix = "\""
		}
		xSplitted := strings.SplitN(x, prefix, 2)
		url := xSplitted[0]

		/*if !strings.Contains(url, "geolocate") {
			continue
		}*/
	/*
			if strings.HasPrefix(url, config.Website.Domain) {
				urls = append(urls, url)
			} else if strings.HasPrefix(url, "/") {
				urls = append(urls, config.Website.Domain+url)
			} else {
				log.Printf("%s is not a valid url or doesn't have the same domain %s\n", url, config.Website.Domain)
			}
		}

		return urls*/
	return nil
}
