package pkg

import (
	"bytes"
	"errors"
	"fmt"
	"io"
	"io/ioutil"
	"net/http"
	"net/url"
	"strings"
	"time"

	"golang.org/x/net/html"
)

func init() {
}

/* Check if the parameter "cb" (or any other defined by flag -cb), the header "origin" or any cookie can be used as cachebuster */
func CheckCache() (CacheStruct, error) {
	// TODO: add time as cachebust indicator?

	var cache CacheStruct
	errorString := "CheckCache: "

	for key, val := range Config.Website.Headers {
		switch strings.ToLower(key) {
		case "cache-control", "pragma":
			for _, val2 := range val {
				switch strings.ToLower(val2) {
				case "no-cache", "no-store":
					msg := fmt.Sprintf("%s is set to %s, so likely the site can't be tested for web cache poisoning. But some caches don't honor this header\n", key, val2)
					PrintVerbose(msg, Yellow, 1)
				}
			}
		case "x-cache", "cf-cache-status", "x-drupal-cache", "x-varnish-cache", "akamai-cache-status":
			cache.Indicator = key
			msg := fmt.Sprintf("%s header was found \n", key)
			PrintVerbose(msg, NoColor, 1)

			cache.AgeIndicator = false
		case "age":
			// only set it it wasn't set to x-cache or sth. similar beforehand
			if cache.Indicator == "" {
				cache.Indicator = key
				msg := fmt.Sprintf("%s header was found \n", key)
				PrintVerbose(msg, NoColor, 1)

				cache.AgeIndicator = true
			}
		}
	}

	if cache.Indicator == "" {
		msg := "No x-cache (or other cache hit/miss header) header was found\n"
		Print(msg, Yellow)
	}

	urlCb, _ := AddCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)

	var req *http.Request
	var err error
	if Config.DoPost {
		req, err = http.NewRequest("POST", urlCb, bytes.NewBufferString(Config.Body))
	} else {
		req, err = http.NewRequest("GET", urlCb, nil)
	}
	if err != nil {
		msg := errorString + err.Error() + "\n"
		Print(msg, Red)
		return cache, errors.New(msg)
	}

	setRequest(req, Config.DoPost)
	waitLimiter(errorString)
	resp, err := http.DefaultClient.Do(req)
	if err != nil {
		msg := errorString + err.Error() + "\n"
		Print(msg, Red)
		if !Config.Force {
			msg := "Use -f/-force to force the test\n"
			Print(msg, Yellow)
		}
		return cache, nil
	}
	defer resp.Body.Close()

	firstUnix := time.Now().Unix()

	if resp.StatusCode != Config.Website.StatusCode {
		msg := errorString + fmt.Sprintf("Unexpected Status Code %d\n", resp.StatusCode)
		Print(msg, Yellow)
	}

	indicValue := strings.TrimSpace(strings.ToLower(resp.Header.Get(cache.Indicator)))
	if checkCacheMiss(indicValue) {
		cache.Parameter = false
		msg := fmt.Sprintf("Parameter %s as CacheBuster is not possible\n", Config.CacheBuster)
		Print(msg, Yellow)
	} else {

		urlCb, _ = AddCacheBuster(Config.Website.Url.String(), "", Config.CacheBuster)

		if Config.DoPost {
			req, err = http.NewRequest("POST", urlCb, bytes.NewBufferString(Config.Body))
		} else {
			req, err = http.NewRequest("GET", urlCb, nil)
		}
		if err != nil {
			msg := errorString + err.Error() + "\n"
			Print(msg, Red)
			return cache, errors.New(msg)
		}

		setRequest(req, Config.DoPost)
		waitLimiter(errorString)

		secondUnix := time.Now().Unix()
		timeDiff := secondUnix - firstUnix
		// make sure that there is at least 2 sec difference.
		// So that first req has Age=0 and second req has Age>=2
		if timeDiff <= 1 && cache.AgeIndicator {
			time.Sleep(2 * time.Second)
		}

		resp, err = http.DefaultClient.Do(req)
		if err != nil {
			msg := errorString + err.Error() + "\n"
			Print(msg, Red)
			return cache, errors.New(msg)
		}
		defer resp.Body.Close()

		if resp.StatusCode != Config.Website.StatusCode {
			msg := fmt.Sprintf("Unexpected Status Code %d\n", resp.StatusCode)
			Print(msg, Yellow)
		}

		indicValue = strings.TrimSpace(strings.ToLower(resp.Header.Get(cache.Indicator)))
		if checkCacheHit(indicValue) {
			cache.Parameter = false
			msg := fmt.Sprintf("Parameter %s as CacheBuster is not possible\n", Config.CacheBuster)
			Print(msg, Yellow)
		} else {
			cache.Parameter = true
			cache.ParameterName = Config.CacheBuster
			msg := fmt.Sprintf("Parameter %s as CacheBuster was successful\n", Config.CacheBuster)
			PrintVerbose(msg, NoColor, 1)
		}
	}

	if !cache.Parameter && !Config.Force {
		msg := "Use -f/-force to force the test\n"
		Print(msg, Yellow)
	}

	return cache, nil
}

/* Simple get request to get the body of a normal response and the cookies */
func GetWebsite(requrl string, setStatusCode bool) (WebsiteStruct, error) {
	var cache CacheStruct
	var web WebsiteStruct

	errorString := "GetWebsite: "

	queryParameterMap := make(map[string]string)

	// get domain
	domainParts := strings.SplitN(requrl, "/", 4)
	domain := domainParts[0] + "//" + domainParts[2]

	// splitting url like {https://www.m10x.de/}?{name=max&role=admin}
	urlSlice := strings.SplitN(requrl, "?", 2)

	// splitting queries like {name=max}&{role=admin}
	var parameterSlice []string
	if strings.Contains(requrl, "?") {
		parameterSlice = strings.Split(urlSlice[1], Config.QuerySeperator)
	}

	if len(parameterSlice) > 0 {
		queryParameterMap = setQueryParameterMap(queryParameterMap, parameterSlice)
	}

	if len(Config.Parameters) > 0 {
		queryParameterMap = setQueryParameterMap(queryParameterMap, Config.Parameters)
	}

	requrl = urlSlice[0] + "?"
	urlNoQueries := urlSlice[0]

	// adding query parameter
	for key, val := range queryParameterMap {
		if !strings.HasSuffix(requrl, "?") {
			requrl += "&"
		}
		requrl += key + "=" + val
	}

	if len(queryParameterMap) > 0 {
		requrl += Config.QuerySeperator
	}

	requrlcb := requrl[:(len(requrl) - 1)]
	if setStatusCode {
		requrlcb, _ = AddCacheBuster(requrl, "", Config.CacheBuster)
	}

	var req *http.Request
	var err error
	if Config.DoPost {
		req, err = http.NewRequest("POST", requrlcb, bytes.NewBufferString(Config.Body))
	} else {
		req, err = http.NewRequest("GET", requrlcb, nil)
	}
	if err != nil {
		msg := errorString + err.Error() + "\n"
		Print(msg, Red)
		return web, errors.New(msg)
	}

	setRequest(req, Config.DoPost)
	waitLimiter(errorString)
	resp, err := http.DefaultClient.Do(req)
	if err != nil {
		msg := errorString + err.Error() + "\n"
		Print(msg, Red)
		return web, errors.New(msg)
	}

	defer resp.Body.Close()

	body, err := ioutil.ReadAll(resp.Body)
	if err != nil {
		msg := errorString + err.Error() + "\n"
		Print(msg, Red)
		return web, errors.New(msg)
	}

	weburl, err := url.Parse(requrl)
	if err != nil {
		msg := errorString + err.Error() + "\n"
		Print(msg, Red)
		return web, errors.New(msg)
	}

	tempStatusCode := Config.StatusCode
	// Only overwrite statuscode if 1. it wasn't set via flag 2. its the first and only request or the second of two requests
	if tempStatusCode == -1 {
		tempStatusCode = resp.StatusCode

		if setStatusCode {
			msg := fmt.Sprintf("The default status code was set to %d\n", tempStatusCode)
			Print(msg, NoColor)
		}
	}

	if setStatusCode {
		cache = Config.Website.Cache
	}

	// if retrieveCookies is false, only the specified cookies will be used
	// otherwise the by the server given cookies AND the specified cookies will be used
	cookiesWebsite := Config.Website.Cookies
	if !Config.DeclineCookies && !setStatusCode {
		cookiesWebsite = append(cookiesWebsite, resp.Cookies()...)
	}

	//weburl.Host:		m.avito.ru
	//weburl.Path:		/
	//weburl.Hostname():m.avito.ru
	//weburl.String():	https://m.avito.ru/?test=12&
	//domain:			https://m.avito.ru
	//urlNoQueries:		https://m.avito.ru/

	web = WebsiteStruct{
		Headers:    resp.Header,
		Body:       string(body),
		Cookies:    cookiesWebsite,
		StatusCode: tempStatusCode,
		Url:        weburl,
		BaseUrlStr: urlNoQueries,
		Queries:    queryParameterMap,
		Cache:      cache,
		Domain:     domain,
		//make map doesnt work here. is now in main method
		//Added:      make(map[string]bool),
	}

	return web, nil
}

func getStatusCode() int {
	var req *http.Request
	var err error
	errorString := "Testing for status code: "
	webUrl := strings.TrimSuffix(Config.Website.Url.String(), "?")

	if Config.DoPost {
		req, err = http.NewRequest("POST", webUrl, bytes.NewBufferString(Config.Body))
	} else {
		req, err = http.NewRequest("GET", webUrl, nil)
	}
	if err != nil {
		msg := errorString + err.Error() + "\n"
		Print(msg, Yellow)
		return -1
	}

	setRequest(req, Config.DoPost)
	waitLimiter(errorString)
	resp, err := http.DefaultClient.Do(req)
	if err != nil {
		msg := errorString + err.Error() + "\n"
		Print(msg, Yellow)
		return -1
	}

	return resp.StatusCode
}

func setQueryParameterMap(queryParameterMap map[string]string, querySlice []string) map[string]string {
	for _, q := range querySlice {
		q = strings.TrimSuffix(q, "\r")
		q = strings.TrimSpace(q)
		if q == "" {
			continue
		} else if !strings.Contains(q, "=") {
			msg := fmt.Sprintf("Specified parameter %s doesn't contain a = and will be skipped\n", q)
			Print(msg, Yellow)
			continue
		} else {
			query := strings.SplitN(q, "=", 2)
			// ok is true, if a query already is set
			val, ok := queryParameterMap[query[0]]
			if ok {
				msg := fmt.Sprintf("Overwriting %s=%s with %s=%s\n", query[0], val, query[0], query[1])
				Print(msg, NoColor)
			}
			queryParameterMap[query[0]] = query[1]
		}
	}

	return queryParameterMap
}

func addDomain(x string, domain string) string {
	if strings.HasPrefix(x, "https://"+domain) || strings.HasPrefix(x, "http://"+domain) {
		return x
	} else if strings.HasPrefix(x, "//") {
		return Config.Website.Domain + x[1:]
	} else if strings.HasPrefix(x, "/") {
		return Config.Website.Domain + x
	} else {
		for i, d := range Config.RecDomains {
			if Config.RecDomains[i] == "" {
				continue
			}
			if strings.HasPrefix(x, "https://"+d) || strings.HasPrefix(x, "http://"+d) {
				return x
			}
		}

		msg := fmt.Sprintf("%s doesn't have %s as domain\n", x, domain)
		PrintVerbose(msg, NoColor, 1)

		return ""
	}
}

func checkRecInclude(x string, recInclude string) bool {
	for _, inc := range strings.Split(recInclude, " ") {
		// remove spaces and skip if someone used multiple spaces instead of one
		// TODO: is it necessary to trim spaces here after splitting for spaces?
		inc = strings.TrimSpace(inc)
		if inc == "" {
			continue
		}
		if strings.Contains(x, inc) {
			return true
		}
	}
	return false
}

func addUrl(urls []string, url string, added map[string]bool, excluded map[string]bool) []string {
	url = addDomain(url, Config.Website.Url.Hostname())

	if url != "" {
		// Check if url isnt added yet and if it satisfies RecInclude (=contains it)
		if excluded[url] {
			msg := fmt.Sprintf("Skipped to add %s to the queue, because it is on the exclude list\n", url)
			PrintVerbose(msg, NoColor, 1)
		} else if added[url] {
			msg := fmt.Sprintf("Skipped to add %s to the queue, because it was already added\n", url)
			PrintVerbose(msg, NoColor, 2)
		} else if Config.RecInclude == "" || checkRecInclude(url, Config.RecInclude) {
			urls = append(urls, url)
			added[url] = true
		} else {
			msg := fmt.Sprintf("Skipped to add %s to the queue, because it doesn't satisfy RecInclude\n", url)
			PrintVerbose(msg, NoColor, 1)
		}
	}

	return urls
}

func CrawlUrls(added map[string]bool, excluded map[string]bool) []string {
	bodyReader := strings.NewReader(Config.Website.Body)
	tokenizer := html.NewTokenizer(bodyReader)

	var urls []string

	eof := false
	for !eof {
		tokentype := tokenizer.Next()

		switch {
		case tokentype == html.StartTagToken:

			token := tokenizer.Token()

			if token.Data == "a" {
				for _, a := range token.Attr {
					if a.Key == "href" {
						urls = addUrl(urls, a.Val, added, excluded)
						break
					}
				}
			} else if token.Data == "script" {
				for _, a := range token.Attr {
					if a.Key == "src" {
						urls = addUrl(urls, a.Val, added, excluded)
						break
					}
				}
			}

		// When EOF is reached a html.ErrorToken appears
		case tokentype == html.ErrorToken:
			err := tokenizer.Err()
			if err == io.EOF {
				eof = true
				break
			}
			msg := fmt.Sprintf("error tokenizing HTML: %v", tokenizer.Err())
			Print(msg, Yellow)
		}
	}

	return urls
}
