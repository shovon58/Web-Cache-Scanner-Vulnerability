package pkg

import (
	"bytes"
	"fmt"
	"io"
	"io/ioutil"
	"net/http"
	"net/url"
	"strings"

	"golang.org/x/net/html"
)

func init() {

}

func CheckCache(client http.Client, config Config) Cache {
	/*
		Wie kann ich erkennen, dass ein Cache aktiv ist?
		- X-Cache : hit / miss
		- Cf-Cache-Status
		- Zeit messen
	*/
	/*
		Was kann ich als Cache Buster benutzen?
		- Query-Parameter (cachebuster)
		- Header (z.B. origin)
	*/
	var cache Cache

	for key, val := range config.Website.Headers {
		switch strings.ToLower(key) {
		case "cache-control", "pragma":
			for _, val2 := range val {
				switch strings.ToLower(val2) {
				case "no-cache":
					msg := fmt.Sprintf("%s is set to no-cache, so likely the site can't be tested for web cache poisoning. But some caches don't honor this header\n", key)
					PrintVerbose(msg, Yellow, 1)
				case "no-store":
					msg := fmt.Sprintf("%s is set to no-store, so likely the site can't be tested for web cache poisoning. But some caches don't honor this header\n", key)
					PrintVerbose(msg, Yellow, 1)
				case "only-if-cached":
					msg := fmt.Sprintf("%s is set to only-if-cached, so likely the site can't be tested for web cache poisoning. But some caches don't honor this header\n", key)
					PrintVerbose(msg, Yellow, 1)
				}
			}
		case "x-cache":
			cache.Indicator = key
			msg := fmt.Sprintf("%s header was found \n", key)
			PrintVerbose(msg, NoColor, 1)
		case "cf-cache-status":
			cache.Indicator = key
			msg := fmt.Sprintf("%s header was found \n", key)
			PrintVerbose(msg, NoColor, 1)
		}
	}

	if cache.Indicator == "" {
		msg := "The x-cache/cf-cache-status header wasn't found\n"
		Print(msg, Yellow)
	}

	urlCb, _ := addCacheBuster(config.Website.Url.String(), "", config.CacheBuster)

	var req *http.Request
	var err error
	if config.DoPost {
		req, err = http.NewRequest("POST", urlCb, bytes.NewBufferString(config.Body))
	} else {
		req, err = http.NewRequest("GET", urlCb, nil)
	}
	if err != nil {
		msg := err.Error() + "\n"
		PrintFatal(msg)
	}

	setRequest(req, config.DoPost, config)

	resp, err := client.Do(req)
	if err != nil {
		msg := err.Error() + "\n"
		PrintFatal(msg)
	}
	defer resp.Body.Close()

	if resp.StatusCode != config.Website.StatusCode {
		msg := fmt.Sprintf("Unexpected Status Code %d\n", resp.StatusCode)
		Print(msg, Yellow)
	}

	if !strings.Contains(strings.ToLower(resp.Header.Get(cache.Indicator)), "miss") {
		cache.Parameter = false
		msg := fmt.Sprintf("Parameter %s as CacheBuster is not possible\n", config.CacheBuster)
		Print(msg, Yellow)
	} else {

		urlCb, _ = addCacheBuster(config.Website.Url.String(), "", config.CacheBuster)

		if config.DoPost {
			req, err = http.NewRequest("POST", urlCb, bytes.NewBufferString(config.Body))
		} else {
			req, err = http.NewRequest("GET", urlCb, nil)
		}
		if err != nil {
			msg := err.Error() + "\n"
			PrintFatal(msg)
		}

		setRequest(req, config.DoPost, config)
		resp, err = client.Do(req)
		if err != nil {
			msg := err.Error() + "\n"
			PrintFatal(msg)
		}
		defer resp.Body.Close()

		if resp.StatusCode != config.Website.StatusCode {
			msg := fmt.Sprintf("Unexpected Status Code %d\n", resp.StatusCode)
			Print(msg, Yellow)
		}

		if strings.Contains(strings.ToLower(resp.Header.Get(cache.Indicator)), "hit") {
			cache.Parameter = false
			msg := fmt.Sprintf("Parameter %s as CacheBuster is not possible\n", config.CacheBuster)
			Print(msg, Yellow)
		} else {
			cache.Parameter = true
			cache.ParameterName = config.CacheBuster
			msg := fmt.Sprintf("Parameter %s as CacheBuster was successful\n", config.CacheBuster)
			PrintVerbose(msg, NoColor, 1)
		}
	}

	if !cache.Parameter && !config.Force {
		msg := "Use -f/-force to force the test\n"
		Print(msg, Yellow)
	}

	return cache
}

/* Simple get request to get the body of a normal response and the cookies */
func GetWebsite(requrl string, client http.Client, retrieveCookies bool, firstRequest bool, config Config) Website {

	var cache Cache

	queryParameterMap := make(map[string]string)

	// get domain
	domainParts := strings.SplitN(requrl, "/", 4)
	domain := domainParts[0] + "//" + domainParts[2]

	// splitting url like {https://www.m10x.de/}?{name=max&role=admin}
	urlSlice := strings.SplitN(requrl, "?", 2)

	// splitting queries like {name=max}&{role=admin}
	var parameterSlice []string
	if strings.Contains(requrl, "?") {
		parameterSlice = strings.Split(urlSlice[1], config.QuerySeperator)
	}

	if len(parameterSlice) > 0 {
		queryParameterMap = setQueryParameterMap(queryParameterMap, parameterSlice)
	}

	if len(config.Parameters) > 0 {
		queryParameterMap = setQueryParameterMap(queryParameterMap, config.Parameters)
	}

	requrl = urlSlice[0] + "?"
	urlNoQueries := urlSlice[0]

	// adding query parameter
	for key, val := range queryParameterMap {
		if !strings.HasSuffix(requrl, "?") {
			requrl += "&"
		}
		requrl += key + "=" + val
	}

	if len(queryParameterMap) > 0 {
		requrl += config.QuerySeperator
	}

	// adding cachebuster
	//requrlcb, _ := addCacheBuster(requrl, "", config.CacheBuster)

	var req *http.Request
	var err error
	if config.DoPost {
		req, err = http.NewRequest("POST", requrl[:(len(requrl)-1)], bytes.NewBufferString(config.Body))
	} else {
		req, err = http.NewRequest("GET", requrl[:(len(requrl)-1)], nil)
	}
	if err != nil {
		msg := err.Error() + "\n"
		PrintFatal(msg)
	}

	setRequest(req, config.DoPost, config)
	resp, err := client.Do(req)
	if err != nil {
		msg := err.Error() + "\n"
		PrintFatal(msg)
	}

	defer resp.Body.Close()

	body, err := ioutil.ReadAll(resp.Body)
	if err != nil {
		msg := err.Error() + "\n"
		PrintFatal(msg)
	}

	weburl, err := url.Parse(requrl)
	if err != nil {
		msg := err.Error() + "\n"
		PrintFatal(msg)
	}

	tempStatusCode := config.StatusCode
	if tempStatusCode == 0 {
		tempStatusCode = resp.StatusCode

		msg := fmt.Sprintf("The default Status Code was set to %d\n", tempStatusCode)
		Print(msg, NoColor)
	}

	// if retrieveCookies is false, only the specified cookies will be used
	// otherwise the by the server given cookies AND the specified cookies will be used
	cookiesWebsite := config.Website.Cookies
	if retrieveCookies {
		cookiesWebsite = append(cookiesWebsite, resp.Cookies()...)
	}

	c := Website{
		Headers:    resp.Header,
		Body:       string(body),
		Cookies:    cookiesWebsite,
		StatusCode: tempStatusCode,
		Url:        weburl,
		BaseUrlStr: urlNoQueries,
		Queries:    queryParameterMap,
		Cache:      cache,
		Domain:     domain,
		//make map doesnt work here. is now in main method
		//Added:      make(map[string]bool),
	}

	return c
}

func setQueryParameterMap(queryParameterMap map[string]string, querySlice []string) map[string]string {
	for _, q := range querySlice {
		q = strings.TrimSuffix(q, "\r")
		q = strings.TrimSpace(q)
		if q == "" {
			continue
		} else if !strings.Contains(q, "=") {
			msg := fmt.Sprintf("Specified parameter %s doesn't contain a = and will be skipped\n", q)
			Print(msg, Yellow)
			continue
		} else {
			query := strings.SplitN(q, "=", 2)
			// ok is true, if a query already is set
			val, ok := queryParameterMap[query[0]]
			if ok {
				msg := fmt.Sprintf("Overwriting %s=%s with %s=%s\n", query[0], val, query[0], query[1])
				Print(msg, NoColor)
			}
			queryParameterMap[query[0]] = query[1]
		}
	}

	return queryParameterMap
}

func addDomain(x string, domain string) string {
	if strings.HasPrefix(x, domain) {
		return x
	} else if strings.HasPrefix(x, "/") {
		return domain + x
	} else {
		msg := fmt.Sprintf("%s doesn't have %s as domain\n", x, domain)
		PrintVerbose(msg, NoColor, 1)

		return ""
	}
}

func checkRecInclude(x string, recInclude string) bool {
	for _, inc := range strings.Split(recInclude, " ") {
		// remove spaces and skip if someone used multiple spaces instead of one
		// TODO: is it necessary to trim spaces here after splitting for spaces?
		inc = strings.TrimSpace(inc)
		if inc == "" {
			continue
		}
		if strings.Contains(x, inc) {
			return true
		}
	}
	return false
}

func addUrl(urls []string, url string, config Config, added map[string]bool, excluded map[string]bool) []string {
	url = addDomain(url, config.Website.Domain)

	if url != "" {
		// Check if url isnt added yet and if it satisfies RecInclude (=contains it)
		if excluded[url] {
			msg := fmt.Sprintf("Skipped to add %s to the queue, because it is on the exclude list\n", url)
			PrintVerbose(msg, NoColor, 1)
		} else if added[url] {
			msg := fmt.Sprintf("Skipped to add %s to the queue, because it was already added\n", url)
			PrintVerbose(msg, NoColor, 2)
		} else if config.RecInclude == "" || checkRecInclude(url, config.RecInclude) {
			urls = append(urls, url)
			added[url] = true
		} else {
			msg := fmt.Sprintf("Skipped to add %s to the queue, because it doesn't satisfy RecInclude\n", url)
			PrintVerbose(msg, NoColor, 1)
		}
	}

	return urls
}

func CrawlUrls(config Config, added map[string]bool, excluded map[string]bool) []string {
	bodyReader := strings.NewReader(config.Website.Body)
	tokenizer := html.NewTokenizer(bodyReader)

	var urls []string

	eof := false
	for !eof {
		tokentype := tokenizer.Next()

		switch {
		case tokentype == html.StartTagToken:

			token := tokenizer.Token()

			if token.Data == "a" {
				for _, a := range token.Attr {
					if a.Key == "href" {
						urls = addUrl(urls, a.Val, config, added, excluded)
						break
					}
				}
			} else if token.Data == "script" {
				for _, a := range token.Attr {
					if a.Key == "src" {
						urls = addUrl(urls, a.Val, config, added, excluded)
						break
					}
				}
			}

		// When EOF is reached a html.ErrorToken appears
		case tokentype == html.ErrorToken:
			err := tokenizer.Err()
			if err == io.EOF {
				eof = true
				break
			}
			msg := fmt.Sprintf("error tokenizing HTML: %v", tokenizer.Err())
			Print(msg, Yellow)
		}
	}

	return urls
}
